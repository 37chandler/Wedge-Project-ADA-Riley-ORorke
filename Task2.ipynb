{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Riley_26\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\cloud\\bigquery\\table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 253.51870441436768 MB\n",
      "Data exported to owner_sample.csv\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "\n",
    "# Deliverable 1: Connects to your GBQ instance\n",
    "client = bigquery.Client()\n",
    "\n",
    "# List of tables from umt-msba project (excluding inactive ones)\n",
    "table_names = [\n",
    "    'transArchive_201001_201003', 'transArchive_201004_201006', 'transArchive_201007_201009', \n",
    "    'transArchive_201010_201012', 'transArchive_201101_201103', 'transArchive_201104', \n",
    "    'transArchive_201105', 'transArchive_201106', 'transArchive_201107_201109', \n",
    "    'transArchive_201110_201112', 'transArchive_201201_201203', 'transArchive_201204_201206', \n",
    "    'transArchive_201207_201209', 'transArchive_201210_201212', 'transArchive_201301_201303', \n",
    "    'transArchive_201304_201306', 'transArchive_201307_201309', 'transArchive_201310_201312', \n",
    "    'transArchive_201401_201403', 'transArchive_201404_201406', 'transArchive_201407_201409', \n",
    "    'transArchive_201410_201412', 'transArchive_201501_201503', 'transArchive_201504_201506', \n",
    "    'transArchive_201507_201509', 'transArchive_201510', 'transArchive_201511', 'transArchive_201512', \n",
    "    'transArchive_201601', 'transArchive_201602', 'transArchive_201603', 'transArchive_201604', \n",
    "    'transArchive_201605', 'transArchive_201606', 'transArchive_201607', 'transArchive_201608', \n",
    "    'transArchive_201609', 'transArchive_201610', 'transArchive_201611', 'transArchive_201612', \n",
    "    'transArchive_201701'\n",
    "]\n",
    "\n",
    "# Deliverable 2: Builds a list of owners\n",
    "# Construct a UNION query across all tables to gather data excluding non-owners (card_no != 3)\n",
    "union_query = \" UNION ALL \".join([\n",
    "    f\"SELECT * FROM `umt-msba.transactions.{table_name}` WHERE card_no != 3\" \n",
    "    for table_name in table_names\n",
    "])\n",
    "\n",
    "# Full query to fetch all owner transactions (sample will be created later)\n",
    "full_query = f\"\"\"\n",
    "    SELECT * FROM ({union_query})\n",
    "    ORDER BY RAND()  -- Randomize the data\n",
    "    LIMIT 425000  -- Adjusting this number adjusts sample size\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and fetch the data\n",
    "df = client.query(full_query).to_dataframe()\n",
    "df = df.groupby('card_no').first().reset_index()\n",
    "\n",
    "# Deliverable 3: Takes a sample of the owners\n",
    "# The sampling is done by the query itself using LIMIT and ORDER BY RAND()\n",
    "\n",
    "# Check the size of the sample\n",
    "print(f\"Data size: {df.memory_usage(deep=True).sum() / (1024 * 1024)} MB\")\n",
    "\n",
    "# Deliverable 4: Extracts all records associated with those owners and writes them to a local text file\n",
    "# Write the sample to a CSV file\n",
    "df.to_csv(\"owner_sample.csv\", index=False)\n",
    "\n",
    "print(\"Data exported to owner_sample.csv\")\n",
    "\n",
    "# This takes around 6 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Riley_26\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\cloud\\bigquery\\table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 13.930037498474121 MB\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "\n",
    "# Deliverable 1: Connects to your GBQ instance\n",
    "client = bigquery.Client()\n",
    "\n",
    "# List of tables from umt-msba project (excluding inactive ones)\n",
    "table_names = [\n",
    "    'transArchive_201001_201003', 'transArchive_201004_201006', 'transArchive_201007_201009', \n",
    "    'transArchive_201010_201012', 'transArchive_201101_201103', 'transArchive_201104', \n",
    "    'transArchive_201105', 'transArchive_201106', 'transArchive_201107_201109', \n",
    "    'transArchive_201110_201112', 'transArchive_201201_201203', 'transArchive_201204_201206', \n",
    "    'transArchive_201207_201209', 'transArchive_201210_201212', 'transArchive_201301_201303', \n",
    "    'transArchive_201304_201306', 'transArchive_201307_201309', 'transArchive_201310_201312', \n",
    "    'transArchive_201401_201403', 'transArchive_201404_201406', 'transArchive_201407_201409', \n",
    "    'transArchive_201410_201412', 'transArchive_201501_201503', 'transArchive_201504_201506', \n",
    "    'transArchive_201507_201509', 'transArchive_201510', 'transArchive_201511', 'transArchive_201512', \n",
    "    'transArchive_201601', 'transArchive_201602', 'transArchive_201603', 'transArchive_201604', \n",
    "    'transArchive_201605', 'transArchive_201606', 'transArchive_201607', 'transArchive_201608', \n",
    "    'transArchive_201609', 'transArchive_201610', 'transArchive_201611', 'transArchive_201612', \n",
    "    'transArchive_201701'\n",
    "]\n",
    "\n",
    "# Deliverable 2: Builds a list of owners\n",
    "# Construct a UNION query across all tables to gather data excluding non-owners (card_no != 3)\n",
    "union_query = \" UNION ALL \".join([\n",
    "    f\"SELECT * FROM `umt-msba.transactions.{table_name}` WHERE card_no != 3\" \n",
    "    for table_name in table_names\n",
    "])\n",
    "\n",
    "# Full query to fetch all owner transactions (sample will be created later)\n",
    "full_query = f\"\"\"\n",
    "    SELECT * FROM ({union_query})\n",
    "    ORDER BY RAND()  -- Randomize the data\n",
    "    LIMIT 1000000  -- Adjusting this number adjusts sample size\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and fetch the data\n",
    "df = client.query(full_query).to_dataframe()\n",
    "df = df.groupby('card_no').first().reset_index()\n",
    "\n",
    "# Deliverable 3: Takes a sample of the owners\n",
    "# The sampling is done by the query itself using LIMIT and ORDER BY RAND()\n",
    "\n",
    "# Check the size of the sample\n",
    "print(f\"Data size: {df.memory_usage(deep=True).sum() / (1024 * 1024)} MB\")\n",
    "\n",
    "# Deliverable 4: Extracts all records associated with those owners and writes them to a local text file\n",
    "# Write the sample to a CSV file\n",
    "# df.to_csv(\"owner_sample.csv\", index=False)\n",
    "\n",
    "# print(\"Data exported to owner_sample.csv\")\n",
    "\n",
    "# This takes around 6 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Riley_26\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\cloud\\bigquery\\table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 16.04214382171631 MB\n",
      "Number of unique owners (card_no): 25941\n",
      "Total rows (should match unique owners): 25941\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "\n",
    "# Deliverable 1: Connect to your GBQ instance\n",
    "client = bigquery.Client()\n",
    "\n",
    "# List of tables from umt-msba project (excluding inactive ones)\n",
    "table_names = [\n",
    "    'transArchive_201001_201003', 'transArchive_201004_201006', 'transArchive_201007_201009', \n",
    "    'transArchive_201010_201012', 'transArchive_201101_201103', 'transArchive_201104', \n",
    "    'transArchive_201105', 'transArchive_201106', 'transArchive_201107_201109', \n",
    "    'transArchive_201110_201112', 'transArchive_201201_201203', 'transArchive_201204_201206', \n",
    "    'transArchive_201207_201209', 'transArchive_201210_201212', 'transArchive_201301_201303', \n",
    "    'transArchive_201304_201306', 'transArchive_201307_201309', 'transArchive_201310_201312', \n",
    "    'transArchive_201401_201403', 'transArchive_201404_201406', 'transArchive_201407_201409', \n",
    "    'transArchive_201410_201412', 'transArchive_201501_201503', 'transArchive_201504_201506', \n",
    "    'transArchive_201507_201509', 'transArchive_201510', 'transArchive_201511', 'transArchive_201512', \n",
    "    'transArchive_201601', 'transArchive_201602', 'transArchive_201603', 'transArchive_201604', \n",
    "    'transArchive_201605', 'transArchive_201606', 'transArchive_201607', 'transArchive_201608', \n",
    "    'transArchive_201609', 'transArchive_201610', 'transArchive_201611', 'transArchive_201612', \n",
    "    'transArchive_201701'\n",
    "]\n",
    "\n",
    "# Step 1: Build a UNION query across all tables, excluding non-owners (card_no != 3)\n",
    "union_query = \" UNION ALL \".join([\n",
    "    f\"SELECT * FROM `umt-msba.transactions.{table_name}` WHERE card_no != 3\" \n",
    "    for table_name in table_names\n",
    "])\n",
    "\n",
    "# Step 2: Sample distinct owners by card_no, ensuring no duplicates, and randomizing\n",
    "distinct_owners_query = f\"\"\"\n",
    "    SELECT card_no,\n",
    "           ANY_VALUE(datetime) AS datetime,\n",
    "           ANY_VALUE(register_no) AS register_no,\n",
    "           ANY_VALUE(emp_no) AS emp_no,\n",
    "           ANY_VALUE(trans_no) AS trans_no,\n",
    "           ANY_VALUE(upc) AS upc,\n",
    "           ANY_VALUE(description) AS description,\n",
    "           ANY_VALUE(trans_type) AS trans_type,\n",
    "           ANY_VALUE(trans_subtype) AS trans_subtype,\n",
    "           ANY_VALUE(trans_status) AS trans_status,\n",
    "           ANY_VALUE(department) AS department,\n",
    "           ANY_VALUE(quantity) AS quantity,\n",
    "           ANY_VALUE(Scale) AS Scale,\n",
    "           ANY_VALUE(cost) AS cost,\n",
    "           ANY_VALUE(unitPrice) AS unitPrice,\n",
    "           ANY_VALUE(total) AS total,\n",
    "           ANY_VALUE(regPrice) AS regPrice,\n",
    "           ANY_VALUE(altPrice) AS altPrice,\n",
    "           ANY_VALUE(tax) AS tax,\n",
    "           ANY_VALUE(taxexempt) AS taxexempt,\n",
    "           ANY_VALUE(foodstamp) AS foodstamp,\n",
    "           ANY_VALUE(wicable) AS wicable,\n",
    "           ANY_VALUE(discount) AS discount,\n",
    "           ANY_VALUE(memDiscount) AS memDiscount,\n",
    "           ANY_VALUE(discountable) AS discountable,\n",
    "           ANY_VALUE(discounttype) AS discounttype,\n",
    "           ANY_VALUE(voided) AS voided,\n",
    "           ANY_VALUE(percentDiscount) AS percentDiscount,\n",
    "           ANY_VALUE(ItemQtty) AS ItemQtty,\n",
    "           ANY_VALUE(volDiscType) AS volDiscType,\n",
    "           ANY_VALUE(volume) AS volume,\n",
    "           ANY_VALUE(VolSpecial) AS VolSpecial,\n",
    "           ANY_VALUE(mixMatch) AS mixMatch,\n",
    "           ANY_VALUE(matched) AS matched,\n",
    "           ANY_VALUE(memType) AS memType,\n",
    "           ANY_VALUE(staff) AS staff,\n",
    "           ANY_VALUE(numflag) AS numflag,\n",
    "           ANY_VALUE(itemstatus) AS itemstatus,\n",
    "           ANY_VALUE(tenderstatus) AS tenderstatus,\n",
    "           ANY_VALUE(charflag) AS charflag,\n",
    "           ANY_VALUE(varflag) AS varflag,\n",
    "           ANY_VALUE(batchHeaderID) AS batchHeaderID,\n",
    "           ANY_VALUE(local) AS local,\n",
    "           ANY_VALUE(organic) AS organic,\n",
    "           ANY_VALUE(display) AS display,\n",
    "           ANY_VALUE(receipt) AS receipt,\n",
    "           ANY_VALUE(store) AS store,\n",
    "           ANY_VALUE(branch) AS branch,\n",
    "           ANY_VALUE(match_id) AS match_id,\n",
    "           ANY_VALUE(trans_id) AS trans_id\n",
    "    FROM ({union_query})\n",
    "    GROUP BY card_no\n",
    "    ORDER BY RAND()\n",
    "    LIMIT 400000  -- Adjust this value to control the number of unique owners\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Step 3: Execute the query to fetch the sampled records\n",
    "df_unique_owners = client.query(distinct_owners_query).to_dataframe()\n",
    "\n",
    "# Step 4: Check the size of the sample\n",
    "print(f\"Data size: {df_unique_owners.memory_usage(deep=True).sum() / (1024 * 1024)} MB\")\n",
    "print(f\"Number of unique owners (card_no): {df_unique_owners['card_no'].nunique()}\")\n",
    "print(f\"Total rows (should match unique owners): {len(df_unique_owners)}\")\n",
    "\n",
    "# Step 5: Write the filtered sample (one record per owner) to a CSV file\n",
    "# df_unique_owners.to_csv(\"owner_sample_one_per_owner.csv\", index=False)\n",
    "\n",
    "# print(\"Data exported to owner_sample_one_per_owner.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Riley_26\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\cloud\\bigquery\\table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 15.85622501373291 MB\n",
      "Number of unique owners (card_no): 25941\n",
      "Total rows (should match unique owners): 25941\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "\n",
    "# Deliverable 1: Connect to your GBQ instance\n",
    "client = bigquery.Client()\n",
    "\n",
    "# List of tables from umt-msba project (excluding inactive ones)\n",
    "table_names = [\n",
    "    'transArchive_201001_201003', 'transArchive_201004_201006', 'transArchive_201007_201009', \n",
    "    'transArchive_201010_201012', 'transArchive_201101_201103', 'transArchive_201104', \n",
    "    'transArchive_201105', 'transArchive_201106', 'transArchive_201107_201109', \n",
    "    'transArchive_201110_201112', 'transArchive_201201_201203', 'transArchive_201204_201206', \n",
    "    'transArchive_201207_201209', 'transArchive_201210_201212', 'transArchive_201301_201303', \n",
    "    'transArchive_201304_201306', 'transArchive_201307_201309', 'transArchive_201310_201312', \n",
    "    'transArchive_201401_201403', 'transArchive_201404_201406', 'transArchive_201407_201409', \n",
    "    'transArchive_201410_201412', 'transArchive_201501_201503', 'transArchive_201504_201506', \n",
    "    'transArchive_201507_201509', 'transArchive_201510', 'transArchive_201511', 'transArchive_201512', \n",
    "    'transArchive_201601', 'transArchive_201602', 'transArchive_201603', 'transArchive_201604', \n",
    "    'transArchive_201605', 'transArchive_201606', 'transArchive_201607', 'transArchive_201608', \n",
    "    'transArchive_201609', 'transArchive_201610', 'transArchive_201611', 'transArchive_201612', \n",
    "    'transArchive_201701'\n",
    "]\n",
    "\n",
    "# Step 1: Build a UNION query across all tables, excluding non-owners (card_no != 3)\n",
    "union_query = \" UNION ALL \".join([\n",
    "    f\"SELECT * FROM `umt-msba.transactions.{table_name}` WHERE card_no != 3\" \n",
    "    for table_name in table_names\n",
    "])\n",
    "\n",
    "# Step 2: Sample distinct owners by card_no, ensuring no duplicates, and randomizing\n",
    "distinct_owners_query = f\"\"\"\n",
    "    SELECT card_no,\n",
    "           ANY_VALUE(datetime) AS datetime,\n",
    "           ANY_VALUE(register_no) AS register_no,\n",
    "           ANY_VALUE(emp_no) AS emp_no,\n",
    "           ANY_VALUE(trans_no) AS trans_no,\n",
    "           ANY_VALUE(upc) AS upc,\n",
    "           ANY_VALUE(description) AS description,\n",
    "           ANY_VALUE(trans_type) AS trans_type,\n",
    "           ANY_VALUE(trans_subtype) AS trans_subtype,\n",
    "           ANY_VALUE(trans_status) AS trans_status,\n",
    "           ANY_VALUE(department) AS department,\n",
    "           ANY_VALUE(quantity) AS quantity,\n",
    "           ANY_VALUE(Scale) AS Scale,\n",
    "           ANY_VALUE(cost) AS cost,\n",
    "           ANY_VALUE(unitPrice) AS unitPrice,\n",
    "           ANY_VALUE(total) AS total,\n",
    "           ANY_VALUE(regPrice) AS regPrice,\n",
    "           ANY_VALUE(altPrice) AS altPrice,\n",
    "           ANY_VALUE(tax) AS tax,\n",
    "           ANY_VALUE(taxexempt) AS taxexempt,\n",
    "           ANY_VALUE(foodstamp) AS foodstamp,\n",
    "           ANY_VALUE(wicable) AS wicable,\n",
    "           ANY_VALUE(discount) AS discount,\n",
    "           ANY_VALUE(memDiscount) AS memDiscount,\n",
    "           ANY_VALUE(discountable) AS discountable,\n",
    "           ANY_VALUE(discounttype) AS discounttype,\n",
    "           ANY_VALUE(voided) AS voided,\n",
    "           ANY_VALUE(percentDiscount) AS percentDiscount,\n",
    "           ANY_VALUE(ItemQtty) AS ItemQtty,\n",
    "           ANY_VALUE(volDiscType) AS volDiscType,\n",
    "           ANY_VALUE(volume) AS volume,\n",
    "           ANY_VALUE(VolSpecial) AS VolSpecial,\n",
    "           ANY_VALUE(mixMatch) AS mixMatch,\n",
    "           ANY_VALUE(matched) AS matched,\n",
    "           ANY_VALUE(memType) AS memType,\n",
    "           ANY_VALUE(staff) AS staff,\n",
    "           ANY_VALUE(numflag) AS numflag,\n",
    "           ANY_VALUE(itemstatus) AS itemstatus,\n",
    "           ANY_VALUE(tenderstatus) AS tenderstatus,\n",
    "           ANY_VALUE(charflag) AS charflag,\n",
    "           ANY_VALUE(varflag) AS varflag,\n",
    "           ANY_VALUE(batchHeaderID) AS batchHeaderID,\n",
    "           ANY_VALUE(local) AS local,\n",
    "           ANY_VALUE(organic) AS organic,\n",
    "           ANY_VALUE(display) AS display,\n",
    "           ANY_VALUE(receipt) AS receipt,\n",
    "           ANY_VALUE(store) AS store,\n",
    "           ANY_VALUE(branch) AS branch,\n",
    "           ANY_VALUE(match_id) AS match_id,\n",
    "           ANY_VALUE(trans_id) AS trans_id\n",
    "    FROM ({union_query})\n",
    "    GROUP BY card_no\n",
    "    ORDER BY RAND()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# LIMIT 1000000  -- Adjust this value to control the number of unique owners\n",
    "# Step 3: Execute the query to fetch the sampled records\n",
    "df_unique_owners = client.query(distinct_owners_query).to_dataframe()\n",
    "\n",
    "# Step 4: Check the size of the sample\n",
    "print(f\"Data size: {df_unique_owners.memory_usage(deep=True).sum() / (1024 * 1024)} MB\")\n",
    "print(f\"Number of unique owners (card_no): {df_unique_owners['card_no'].nunique()}\")\n",
    "print(f\"Total rows (should match unique owners): {len(df_unique_owners)}\")\n",
    "\n",
    "# Step 5: Write the filtered sample (one record per owner) to a CSV file\n",
    "# df_unique_owners.to_csv(\"owner_sample_one_per_owner.csv\", index=False)\n",
    "\n",
    "# print(\"Data exported to owner_sample_one_per_owner.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Riley_26\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\cloud\\bigquery\\table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 0.6115951538085938 MB\n",
      "Estimated number of rows needed for ~250 MB: 408767\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "\n",
    "# Deliverable 1: Connect to your GBQ instance\n",
    "client = bigquery.Client()\n",
    "\n",
    "# List of tables from umt-msba project (excluding inactive ones)\n",
    "table_names = [\n",
    "    'transArchive_201001_201003', 'transArchive_201004_201006', 'transArchive_201007_201009', \n",
    "    'transArchive_201010_201012', 'transArchive_201101_201103', 'transArchive_201104', \n",
    "    'transArchive_201105', 'transArchive_201106', 'transArchive_201107_201109', \n",
    "    'transArchive_201110_201112', 'transArchive_201201_201203', 'transArchive_201204_201206', \n",
    "    'transArchive_201207_201209', 'transArchive_201210_201212', 'transArchive_201301_201303', \n",
    "    'transArchive_201304_201306', 'transArchive_201307_201309', 'transArchive_201310_201312', \n",
    "    'transArchive_201401_201403', 'transArchive_201404_201406', 'transArchive_201407_201409', \n",
    "    'transArchive_201410_201412', 'transArchive_201501_201503', 'transArchive_201504_201506', \n",
    "    'transArchive_201507_201509', 'transArchive_201510', 'transArchive_201511', 'transArchive_201512', \n",
    "    'transArchive_201601', 'transArchive_201602', 'transArchive_201603', 'transArchive_201604', \n",
    "    'transArchive_201605', 'transArchive_201606', 'transArchive_201607', 'transArchive_201608', \n",
    "    'transArchive_201609', 'transArchive_201610', 'transArchive_201611', 'transArchive_201612', \n",
    "    'transArchive_201701'\n",
    "]\n",
    "\n",
    "# Step 1: Build a UNION query across all tables, excluding non-owners (card_no != 3)\n",
    "union_query = \" UNION ALL \".join([\n",
    "    f\"SELECT * FROM `umt-msba.transactions.{table_name}` WHERE card_no != 3\" \n",
    "    for table_name in table_names\n",
    "])\n",
    "\n",
    "# Step 2: Sample distinct owners by card_no, ensuring no duplicates, and randomizing\n",
    "# Start with a small sample for estimation (e.g., LIMIT 1000)\n",
    "sample_query = f\"\"\"\n",
    "    SELECT card_no,\n",
    "           ANY_VALUE(datetime) AS datetime,\n",
    "           ANY_VALUE(register_no) AS register_no,\n",
    "           ANY_VALUE(emp_no) AS emp_no,\n",
    "           ANY_VALUE(trans_no) AS trans_no,\n",
    "           ANY_VALUE(upc) AS upc,\n",
    "           ANY_VALUE(description) AS description,\n",
    "           ANY_VALUE(trans_type) AS trans_type,\n",
    "           ANY_VALUE(trans_subtype) AS trans_subtype,\n",
    "           ANY_VALUE(trans_status) AS trans_status,\n",
    "           ANY_VALUE(department) AS department,\n",
    "           ANY_VALUE(quantity) AS quantity,\n",
    "           ANY_VALUE(Scale) AS Scale,\n",
    "           ANY_VALUE(cost) AS cost,\n",
    "           ANY_VALUE(unitPrice) AS unitPrice,\n",
    "           ANY_VALUE(total) AS total,\n",
    "           ANY_VALUE(regPrice) AS regPrice,\n",
    "           ANY_VALUE(altPrice) AS altPrice,\n",
    "           ANY_VALUE(tax) AS tax,\n",
    "           ANY_VALUE(taxexempt) AS taxexempt,\n",
    "           ANY_VALUE(foodstamp) AS foodstamp,\n",
    "           ANY_VALUE(wicable) AS wicable,\n",
    "           ANY_VALUE(discount) AS discount,\n",
    "           ANY_VALUE(memDiscount) AS memDiscount,\n",
    "           ANY_VALUE(discountable) AS discountable,\n",
    "           ANY_VALUE(discounttype) AS discounttype,\n",
    "           ANY_VALUE(voided) AS voided,\n",
    "           ANY_VALUE(percentDiscount) AS percentDiscount,\n",
    "           ANY_VALUE(ItemQtty) AS ItemQtty,\n",
    "           ANY_VALUE(volDiscType) AS volDiscType,\n",
    "           ANY_VALUE(volume) AS volume,\n",
    "           ANY_VALUE(VolSpecial) AS VolSpecial,\n",
    "           ANY_VALUE(mixMatch) AS mixMatch,\n",
    "           ANY_VALUE(matched) AS matched,\n",
    "           ANY_VALUE(memType) AS memType,\n",
    "           ANY_VALUE(staff) AS staff,\n",
    "           ANY_VALUE(numflag) AS numflag,\n",
    "           ANY_VALUE(itemstatus) AS itemstatus,\n",
    "           ANY_VALUE(tenderstatus) AS tenderstatus,\n",
    "           ANY_VALUE(charflag) AS charflag,\n",
    "           ANY_VALUE(varflag) AS varflag,\n",
    "           ANY_VALUE(batchHeaderID) AS batchHeaderID,\n",
    "           ANY_VALUE(local) AS local,\n",
    "           ANY_VALUE(organic) AS organic,\n",
    "           ANY_VALUE(display) AS display,\n",
    "           ANY_VALUE(receipt) AS receipt,\n",
    "           ANY_VALUE(store) AS store,\n",
    "           ANY_VALUE(branch) AS branch,\n",
    "           ANY_VALUE(match_id) AS match_id,\n",
    "           ANY_VALUE(trans_id) AS trans_id\n",
    "    FROM ({union_query})\n",
    "    GROUP BY card_no\n",
    "    ORDER BY RAND()\n",
    "    LIMIT 1000  -- Take a small sample for estimation\n",
    "\"\"\"\n",
    "\n",
    "# Step 3: Execute the query to fetch the small sample\n",
    "df_sample = client.query(sample_query).to_dataframe()\n",
    "\n",
    "# Step 4: Check the size of the small sample\n",
    "sample_size_mb = df_sample.memory_usage(deep=True).sum() / (1024 * 1024)\n",
    "print(f\"Sample size: {sample_size_mb} MB\")\n",
    "\n",
    "# Step 5: Estimate the number of rows needed for 250 MB\n",
    "# If 1000 rows = sample_size_mb, then target_rows = (250 / sample_size_mb) * 1000\n",
    "target_rows = int((250 / sample_size_mb) * 1000)\n",
    "print(f\"Estimated number of rows needed for ~250 MB: {target_rows}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
