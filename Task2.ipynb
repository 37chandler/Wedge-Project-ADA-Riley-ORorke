{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "\n",
    "# Deliverable 1: Connects to your GBQ instance\n",
    "client = bigquery.Client()\n",
    "\n",
    "# List of tables from umt-msba project (excluding inactive ones)\n",
    "table_names = [\n",
    "    'transArchive_201001_201003', 'transArchive_201004_201006', 'transArchive_201007_201009', \n",
    "    'transArchive_201010_201012', 'transArchive_201101_201103', 'transArchive_201104', \n",
    "    'transArchive_201105', 'transArchive_201106', 'transArchive_201107_201109', \n",
    "    'transArchive_201110_201112', 'transArchive_201201_201203', 'transArchive_201204_201206', \n",
    "    'transArchive_201207_201209', 'transArchive_201210_201212', 'transArchive_201301_201303', \n",
    "    'transArchive_201304_201306', 'transArchive_201307_201309', 'transArchive_201310_201312', \n",
    "    'transArchive_201401_201403', 'transArchive_201404_201406', 'transArchive_201407_201409', \n",
    "    'transArchive_201410_201412', 'transArchive_201501_201503', 'transArchive_201504_201506', \n",
    "    'transArchive_201507_201509', 'transArchive_201510', 'transArchive_201511', 'transArchive_201512', \n",
    "    'transArchive_201601', 'transArchive_201602', 'transArchive_201603', 'transArchive_201604', \n",
    "    'transArchive_201605', 'transArchive_201606', 'transArchive_201607', 'transArchive_201608', \n",
    "    'transArchive_201609', 'transArchive_201610', 'transArchive_201611', 'transArchive_201612', \n",
    "    'transArchive_201701'\n",
    "]\n",
    "\n",
    "# Deliverable 2: Builds a list of owners\n",
    "# Construct a UNION query across all tables to gather data excluding non-owners (card_no != 3)\n",
    "union_query = \" UNION ALL \".join([\n",
    "    f\"SELECT * FROM `umt-msba.transactions.{table_name}` WHERE card_no != 3\" \n",
    "    for table_name in table_names\n",
    "])\n",
    "\n",
    "# Full query to fetch all owner transactions\n",
    "full_query = f\"\"\"\n",
    "    SELECT * FROM ({union_query})\n",
    "    ORDER BY RAND()  -- Randomize the data\n",
    "    LIMIT 425000  -- Adjusting this number adjusts sample size\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and fetch the data\n",
    "df = client.query(full_query).to_dataframe()\n",
    "\n",
    "# Deliverable 3: Takes a sample of the owners\n",
    "# The sampling is done by the query itself using LIMIT and ORDER BY RAND()\n",
    "\n",
    "# Check the size of the sample\n",
    "print(f\"Data size: {df.memory_usage(deep=True).sum() / (1024 * 1024)} MB\")\n",
    "\n",
    "# Deliverable 4: Extracts all records associated with those owners and writes them to a local text file\n",
    "# Write the sample to a CSV file\n",
    "df.to_csv(\"owner_sample.csv\", index=False)\n",
    "\n",
    "print(\"Data exported to owner_sample.csv\")\n",
    "\n",
    "# This takes around 6 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Riley_26\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\cloud\\bigquery\\table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Riley_26\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\cloud\\bigquery\\table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled transactions extracted and saved to owner_transactions.csv\n",
      "Data size: 370.1079978942871 MB\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to your GBQ instance\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Define the project and dataset\n",
    "project_id = \"umt-msba\"\n",
    "dataset_id = \"transactions\"\n",
    "\n",
    "# Define the list of table names\n",
    "table_names = [\n",
    "    'transArchive_201001_201003', 'transArchive_201004_201006', 'transArchive_201007_201009',\n",
    "    'transArchive_201010_201012', 'transArchive_201101_201103', 'transArchive_201104', \n",
    "    'transArchive_201105', 'transArchive_201106', 'transArchive_201107_201109', \n",
    "    'transArchive_201110_201112', 'transArchive_201201_201203', 'transArchive_201204_201206', \n",
    "    'transArchive_201207_201209', 'transArchive_201210_201212', 'transArchive_201301_201303', \n",
    "    'transArchive_201304_201306', 'transArchive_201307_201309', 'transArchive_201310_201312', \n",
    "    'transArchive_201401_201403', 'transArchive_201404_201406', 'transArchive_201407_201409', \n",
    "    'transArchive_201410_201412', 'transArchive_201501_201503', 'transArchive_201504_201506', \n",
    "    'transArchive_201507_201509', 'transArchive_201510', 'transArchive_201511', 'transArchive_201512', \n",
    "    'transArchive_201601', 'transArchive_201602', 'transArchive_201603', 'transArchive_201604', \n",
    "    'transArchive_201605', 'transArchive_201606', 'transArchive_201607', 'transArchive_201608', \n",
    "    'transArchive_201609', 'transArchive_201610', 'transArchive_201611', 'transArchive_201612', \n",
    "    'transArchive_201701'\n",
    "]\n",
    "\n",
    "# Control the sample size with a variable\n",
    "sample_size = 300\n",
    "\n",
    "# Sample owners directly within BigQuery\n",
    "owner_query = f\"\"\"\n",
    "    WITH unique_owners AS (\n",
    "        SELECT DISTINCT card_no\n",
    "        FROM `{project_id}.{dataset_id}.{table_names[0]}`\n",
    "        WHERE card_no != 3\n",
    "    )\n",
    "    SELECT card_no\n",
    "    FROM unique_owners\n",
    "    ORDER BY RAND()\n",
    "    LIMIT {sample_size}\n",
    "\"\"\"\n",
    "sampled_owners_df = client.query(owner_query).to_dataframe()\n",
    "\n",
    "# Convert owners to a list\n",
    "owner_list = sampled_owners_df['card_no'].tolist()\n",
    "\n",
    "# Define the batch size for the IN clause\n",
    "batch_size = 150\n",
    "\n",
    "# Function to query transactions for a batch of owners\n",
    "def fetch_transactions(owner_batch):\n",
    "    owner_str = ','.join(map(str, owner_batch))\n",
    "    union_all_query = \" UNION ALL \".join([f\"\"\"\n",
    "        SELECT * FROM `{project_id}.{dataset_id}.{table_name}`\n",
    "        WHERE card_no IN ({owner_str})\n",
    "    \"\"\" for table_name in table_names])\n",
    "\n",
    "    return client.query(union_all_query).to_dataframe()\n",
    "\n",
    "# Save results in batches to avoid memory overload\n",
    "output_file = 'owner_transactions.csv'\n",
    "first_write = True\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    for i in range(0, len(owner_list), batch_size):\n",
    "        owner_batch = owner_list[i:i+batch_size]\n",
    "        transaction_df = fetch_transactions(owner_batch)\n",
    "        \n",
    "        # Write to CSV\n",
    "        transaction_df.to_csv(f, header=first_write, index=False, mode='a', lineterminator='\\n')\n",
    "        first_write = False  # Ensure header is only written once\n",
    "\n",
    "\n",
    "print(f\"Sampled transactions extracted and saved to {output_file}\")\n",
    "print(f\"Data size: {transaction_df.memory_usage(deep=True).sum() / (1024 * 1024)} MB\")\n",
    "\n",
    "# This takes about 11 minutes to run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
