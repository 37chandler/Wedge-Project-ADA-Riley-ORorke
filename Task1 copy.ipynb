{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Extract the Main Zip File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping transArchive_201001_201003.zip, already exists.\n",
      "Skipping transArchive_201004_201006.zip, already exists.\n",
      "Skipping transArchive_201007_201009.zip, already exists.\n",
      "Skipping transArchive_201010_201012.zip, already exists.\n",
      "Skipping transArchive_201101_201103.zip, already exists.\n",
      "Skipping transArchive_201104.zip, already exists.\n",
      "Skipping transArchive_201105.zip, already exists.\n",
      "Skipping transArchive_201106.zip, already exists.\n",
      "Skipping transArchive_201107_201109.zip, already exists.\n",
      "Skipping transArchive_201110_201112.zip, already exists.\n",
      "Skipping transArchive_201201_201203.zip, already exists.\n",
      "Skipping transArchive_201201_201203_inactive.zip, marked as inactive.\n",
      "Skipping transArchive_201204_201206.zip, already exists.\n",
      "Skipping transArchive_201204_201206_inactive.zip, marked as inactive.\n",
      "Skipping transArchive_201207_201209.zip, already exists.\n",
      "Skipping transArchive_201207_201209_inactive.zip, marked as inactive.\n",
      "Skipping transArchive_201210_201212.zip, already exists.\n",
      "Skipping transArchive_201210_201212_inactive.zip, marked as inactive.\n",
      "Skipping transArchive_201301_201303.zip, already exists.\n",
      "Skipping transArchive_201301_201303_inactive.zip, marked as inactive.\n",
      "Skipping transArchive_201304_201306.zip, already exists.\n",
      "Skipping transArchive_201304_201306_inactive.zip, marked as inactive.\n",
      "Skipping transArchive_201307_201309.zip, already exists.\n",
      "Skipping transArchive_201307_201309_inactive.zip, marked as inactive.\n",
      "Skipping transArchive_201310_201312.zip, already exists.\n",
      "Skipping transArchive_201310_201312_inactive.zip, marked as inactive.\n",
      "Skipping transArchive_201401_201403.zip, already exists.\n",
      "Skipping transArchive_201401_201403_inactive.zip, marked as inactive.\n",
      "Skipping transArchive_201404_201406.zip, already exists.\n",
      "Skipping transArchive_201404_201406_inactive.zip, marked as inactive.\n",
      "Skipping transArchive_201407_201409.zip, already exists.\n",
      "Skipping transArchive_201407_201409_inactive.zip, marked as inactive.\n",
      "Skipping transArchive_201410_201412.zip, already exists.\n",
      "Skipping transArchive_201410_201412_inactive.zip, marked as inactive.\n",
      "Skipping transArchive_201501_201503.zip, already exists.\n",
      "Skipping transArchive_201504_201506.zip, already exists.\n",
      "Skipping transArchive_201507_201509.zip, already exists.\n",
      "Skipping transArchive_201510.zip, already exists.\n",
      "Skipping transArchive_201511.zip, already exists.\n",
      "Skipping transArchive_201512.zip, already exists.\n",
      "Skipping transArchive_201601.zip, already exists.\n",
      "Skipping transArchive_201602.zip, already exists.\n",
      "Skipping transArchive_201603.zip, already exists.\n",
      "Skipping transArchive_201604.zip, already exists.\n",
      "Skipping transArchive_201605.zip, already exists.\n",
      "Skipping transArchive_201606.zip, already exists.\n",
      "Skipping transArchive_201607.zip, already exists.\n",
      "Skipping transArchive_201608.zip, already exists.\n",
      "Skipping transArchive_201609.zip, already exists.\n",
      "Skipping transArchive_201610.zip, already exists.\n",
      "Skipping transArchive_201611.zip, already exists.\n",
      "Skipping transArchive_201612.zip, already exists.\n",
      "Skipping transArchive_201701.zip, already exists.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def extract_main_zip(main_zip_file, extract_to_folder):\n",
    "    # Ensure the extraction folder exists\n",
    "    os.makedirs(extract_to_folder, exist_ok=True)\n",
    "\n",
    "    # Open the main zip file\n",
    "    with zipfile.ZipFile(main_zip_file, 'r') as main_zip:\n",
    "        # Loop through all files in the main zip file\n",
    "        for zip_info in main_zip.infolist():\n",
    "            # Skip files with \"_inactive\" in their names\n",
    "            if '_inactive' in zip_info.filename:\n",
    "                print(f\"Skipping {zip_info.filename}, marked as inactive.\")\n",
    "                continue\n",
    "            \n",
    "            # Create the full output path\n",
    "            output_file_path = os.path.join(extract_to_folder, zip_info.filename)\n",
    "            \n",
    "            # Check if the file already exists\n",
    "            if not os.path.exists(output_file_path):\n",
    "                # Create any necessary directories\n",
    "                os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "                \n",
    "                # Extract the file\n",
    "                with main_zip.open(zip_info) as source, open(output_file_path, 'wb') as target:\n",
    "                    shutil.copyfileobj(source, target)\n",
    "                print(f\"Extracted {zip_info.filename} to {output_file_path}\")\n",
    "            else:\n",
    "                print(f\"Skipping {zip_info.filename}, already exists.\")\n",
    "\n",
    "# Example usage\n",
    "main_zip = 'D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/WedgeZipOfZips(raw).zip'\n",
    "extract_folder = 'D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_main_zip'\n",
    "\n",
    "extract_main_zip(main_zip, extract_folder)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Extract the Nested Zip Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping transArchive_201001_201003.csv, already exists.\n",
      "Skipping transArchive_201004_201006.csv, already exists.\n",
      "Skipping transArchive_201007_201009.csv, already exists.\n",
      "Skipping transArchive_201010_201012.csv, already exists.\n",
      "Skipping transArchive_201101_201103.csv, already exists.\n",
      "Skipping transArchive_201104.csv, already exists.\n",
      "Skipping transArchive_201105.csv, already exists.\n",
      "Skipping transArchive_201106.csv, already exists.\n",
      "Skipping transArchive_201107_201109.csv, already exists.\n",
      "Skipping transArchive_201110_201112.csv, already exists.\n",
      "Skipping transArchive_201201_201203.csv, already exists.\n",
      "Skipping transArchive_201204_201206.csv, already exists.\n",
      "Skipping transArchive_201207_201209.csv, already exists.\n",
      "Skipping transArchive_201210_201212.csv, already exists.\n",
      "Skipping transArchive_201301_201303.csv, already exists.\n",
      "Skipping transArchive_201304_201306.csv, already exists.\n",
      "Skipping transArchive_201307_201309.csv, already exists.\n",
      "Skipping transArchive_201310_201312.csv, already exists.\n",
      "Skipping transArchive_201401_201403.csv, already exists.\n",
      "Skipping transArchive_201404_201406.csv, already exists.\n",
      "Skipping transArchive_201407_201409.csv, already exists.\n",
      "Skipping transArchive_201410_201412.csv, already exists.\n",
      "Skipping transArchive_201501_201503.csv, already exists.\n",
      "Skipping transArchive_201504_201506.csv, already exists.\n",
      "Skipping transArchive_201507_201509.csv, already exists.\n",
      "Skipping transArchive_201510.csv, already exists.\n",
      "Skipping transArchive_201511.csv, already exists.\n",
      "Skipping transArchive_201512.csv, already exists.\n",
      "Skipping transArchive_201601.csv, already exists.\n",
      "Skipping transArchive_201602.csv, already exists.\n",
      "Skipping transArchive_201603.csv, already exists.\n",
      "Skipping transArchive_201604.csv, already exists.\n",
      "Skipping transArchive_201605.csv, already exists.\n",
      "Skipping transArchive_201606.csv, already exists.\n",
      "Skipping transArchive_201607.csv, already exists.\n",
      "Skipping transArchive_201608.csv, already exists.\n",
      "Skipping transArchive_201609.csv, already exists.\n",
      "Skipping transArchive_201610.csv, already exists.\n",
      "Skipping transArchive_201611.csv, already exists.\n",
      "Skipping transArchive_201612.csv, already exists.\n",
      "Skipping transArchive_201701.csv, already exists.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "def extract_all_csvs_to_one_folder(extract_folder, output_folder):\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Walk through the extracted folder and look for zip files\n",
    "    for root, dirs, files in os.walk(extract_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.zip'):\n",
    "                nested_zip_path = os.path.join(root, file)\n",
    "                \n",
    "                # Check if the file is a valid zip file before proceeding\n",
    "                try:\n",
    "                    with zipfile.ZipFile(nested_zip_path, 'r') as nested_zip:\n",
    "                        for zip_info in nested_zip.infolist():\n",
    "                            if zip_info.filename.endswith('.csv'):\n",
    "                                output_file_path = os.path.join(output_folder, zip_info.filename)\n",
    "                                # Check if the CSV file already exists in the output folder\n",
    "                                if not os.path.exists(output_file_path):\n",
    "                                    # Extract the CSV if it doesn't already exist\n",
    "                                    nested_zip.extract(zip_info, output_folder)\n",
    "                                    print(f\"Extracted {zip_info.filename} to {output_folder}\")\n",
    "                                else:\n",
    "                                    print(f\"Skipping {zip_info.filename}, already exists.\")\n",
    "                except zipfile.BadZipFile:\n",
    "                    print(f\"Skipping {nested_zip_path}, not a valid zip file.\")\n",
    "\n",
    "# Example usage\n",
    "extract_folder = 'D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_main_zip'\n",
    "output_folder = 'D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files'  \n",
    "\n",
    "extract_all_csvs_to_one_folder(extract_folder, output_folder)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Clean and Standardize the CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201001_201003.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201004_201006.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201007_201009.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201010_201012.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201101_201103.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201104.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201105.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201106.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201107_201109.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201110_201112.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201201_201203.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201204_201206.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201207_201209.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201210_201212.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201301_201303.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201304_201306.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201307_201309.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201310_201312.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201401_201403.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201404_201406.csv in memory\n",
      "Error processing D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201407_201409.csv: unexpected end of data\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201410_201412.csv in memory\n",
      "Error processing D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201501_201503.csv: ',' expected after '\"'\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201504_201506.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201507_201509.csv in memory\n",
      "Error processing D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201510.csv: ',' expected after '\"'\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201511.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201512.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201601.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201602.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201603.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201604.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201605.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201606.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201607.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201608.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201609.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201610.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201611.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201612.csv in memory\n",
      "Cleaned D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files\\transArchive_201701.csv in memory\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def clean_and_standardize_file(input_file):\n",
    "    try:\n",
    "        # Detect delimiter automatically and load the CSV\n",
    "        df = pd.read_csv(input_file, sep=None, engine='python')\n",
    "        \n",
    "        # Replace different forms of NULL values with None/NaN (using raw strings to avoid Unicode escape error)\n",
    "        df.replace({\"NULL\": None, r\"\\\\N\": None, r\"\\N\": None}, inplace=True)\n",
    "        \n",
    "        print(f\"Cleaned {input_file} in memory\")\n",
    "        return df  # Return the cleaned dataframe for further processing\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {input_file}: {e}\")\n",
    "        return None  # Return None in case of an error\n",
    "\n",
    "def process_extracted_csvs_in_memory(extracted_folder):\n",
    "    # Get all CSV files in the extracted folder\n",
    "    csv_files = glob.glob(f\"{extracted_folder}/**/*.csv\", recursive=True)\n",
    "    \n",
    "    cleaned_dfs = []\n",
    "    \n",
    "    # Clean and store each CSV file in memory\n",
    "    for csv_file in csv_files:\n",
    "        df = clean_and_standardize_file(csv_file)\n",
    "        if df is not None:\n",
    "            cleaned_dfs.append(df)  # Store cleaned dataframe in the list\n",
    "\n",
    "    return cleaned_dfs  # Return the list of cleaned dataframes\n",
    "\n",
    "# Example usage\n",
    "extracted_folder = 'D:/WedgeProject/Wedge-Project-ADA-Riley-ORorke/data/extracted_csv_files'  # Folder where your extracted CSVs are located\n",
    "\n",
    "# Process and clean all CSVs in memory\n",
    "cleaned_dataframes = process_extracted_csvs_in_memory(extracted_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
